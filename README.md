# Image-Captioning
## The project is to caption images and translate the captions into a regional language (Hindi and Telugu in this case) using an end-to-end deep learning architecture.
Dataset consists of first 5000 image-caption pairs from the COCO dataset.

## Instructions:
1. Open Jupyter Notebook
2. 'preprocessing.ipynb' file is to give a general idea of what image processing operations are applied on the image samples.
3. Open 'Image_captioning_model1.ipynb' file and execute each block of code sequentially.
